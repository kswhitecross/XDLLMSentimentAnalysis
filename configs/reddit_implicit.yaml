
exp:
  d1_name: sample
  d1_split: split1
  d2_name: sample
  d2_split: split2
  max_generate: 256
  name: reddit_implicit_questions_experiment
  num_in_context_samples: 2
  num_inquiry_samples: null
  num_outputs_per_prompt: 5
  prompt_name: april_24_prompt_singular_question.txt
model:
  gen:
    do_sample: true
    max_new_tokens: 2000
    temperature: 0.6
    top_p: 0.9
  name: meta-llama/Llama-3.1-8B-Instruct
  quantize: false
  type: hf
  use_flash_attn: true
name: reddit_implicit_8B
name_id: null
run_id: null
save_context: true
save_dir: runs/reddit/implicit
save_path: null
short_circuit: false
verbose: false
