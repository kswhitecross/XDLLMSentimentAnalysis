dont_save: null
exp:
  d1_name: sample
  d1_split: split1
  d2_name: sample
  d2_split: split2
  max_generate: 256
  name: sample_experiment
  num_in_context_samples: 2
  num_inquiry_samples: null
  num_outputs_per_prompt: 1
  prompt_name: SampleExperimentPrompt.txt
model:
  gen:
    do_sample: true
    max_new_tokens: 2000
    temperature: 0.6
    top_p: 0.9
  name: meta-llama/Llama-3.2-1B-Instruct
  quantize: false
  type: hf
  use_flash_attn: true
name: default
name_id: null
run_id: null
save_context: true
save_dir: runs/
save_path: null
short_circuit: false
verbose: false
